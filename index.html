<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <title>Jinqiang Yu : Home</title>
        <link rel="icon" type="image/icon" href="assets/images/tabicon.ico">

        <link rel="stylesheet" type="text/css" href="">
        <link href="assets/css/bootstrap.min.css" rel="stylesheet">
        <link href="assets/css/bootstrap-theme.min.css" rel="stylesheet">
        <link href="assets/css/font-awesome.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,600,700,700i" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,700,700i|Josefin+Sans:700" rel="stylesheet">
        <link href="assets/css/main.css" rel="stylesheet">
        <link rel="icon" href="assets/images/logo.png">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
        
    </head>
    
    <body>
        <div id="index">                                           <!-- Index starts here -->
            <div class="container main">
                <div class="row home">
                    <div id = "index_left" class="col-md-4 left">
                        <br>
                        <br>
                        <br>
                        <br>
                        <img class="img-responsive img-rabbit" src="assets/images/home.jpg" width="200">
                    </div>
                    <div id = "index_right" class="col-md-6 text-center right">
                        <div class="logo">
                            <img src="assets/images/logo.png">
                            <h4>Jinqiang Yu</h4>
                        </div>
                        <!--<p class="home-description"> -->
                        <p class="fk-description">
                            PhD candidate at Department of Data Science &amp AI, Faculty of Information Technology, Monash University, supervised by Prof. Peter J. Stuckey and Dr. Alexey Ignatiev. 
                        </p>
                        
                        <p class="emailclass" style="font-size:18px">
                            Email: jinqiang.yuuu@gmail.com
                        </p>
                        
                        <div class="btn-group-vertical custom_btn animated slideinright">
                            <a class="btn btn-rabbit" href="https://jinqiang-yu.github.io/assets/cv/cv.pdf">Curriculum Vitae</a>
                            <!-- <div class="btn btn-rabbit" href="https://FrankieJinqiangYu.github.io/assets/cv/cv.pdf">Curriculum Vitae</div> -->
                        </div>      
                        <div class="social">
                            <a href="https://scholar.google.com/citations?user=2_o5eloAAAAJ&hl=en"><i class="fa fa-google" aria-hidden="true"></i></a>
                            <a href="https://www.linkedin.com/in/jinqiang-yu-404bb0187/"><i class="fa fa-linkedin" aria-hidden="true"></i></a>                            
                        </div>
                    </div>                    
                </div>
                
                <br>
                <br>
                <p class='subtitle'>
                    Research Interests
                </p>
                <p class="info" style="font-size:18px"> 
                    Explainable AI, Machine Learning, LLM, GenAI, NLP, CV
                </p>  
                <br>
                <br>
                
                <p class='subtitle'>
                    Publications
                </p>
                <ol class="bibliography">
		    <li>                    
                        <div id="yis-cp23">  
                            <span class="title">
                                From Formal Boosted Tree Explanations to Interpretable Rule Sets
                            </span>
                            <span class="author">
                                <em>Jinqiang Yu,</em>
                                <a href="https://alexeyignatiev.github.io/" target="_blank">Alexey Ignatiev</a>,  
                                and <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>
                            </span>
                            <span class="venue">
                                <i>
                                29th International Conference on Principles and Practice of Constraint Programming (CP), 2023
				</i>
                            </span>
			     <span class="abstract.hidden">
			    <p>The rapid rise of Artificial Intelligence (AI) and Machine Learning (ML) has invoked the need for explainable AI (XAI). One of the most prominent approaches to XAI is to train rule-based ML models, e.g. decision trees, lists and sets, that are deemed interpretable due to their transparent nature. Recent years have witnessed a large body of work in the area of constraints- and reasoning-based approaches to the inference of interpretable models, in particular decision sets (DSes). Despite being shown to outperform heuristic approaches in terms of accuracy, most of them suffer from scalability issues and often fail to handle large training data, in which case no solution is offered. Motivated by this limitation and the success of gradient boosted trees, we propose a novel anytime approach to producing DSes that are both accurate and interpretable. The approach makes use of the concept of a generalized formal explanation and builds on the recent advances in formal explainability of gradient boosted trees. Experimental results obtained on a wide range of datasets, demonstrate that our approach produces DSes that more accurate than those of the state-of-the-art algorithms and comparable with them in terms of explanation size.</p>
			    </span>
                            <span class="links">
                                [<a href="https://jinqiang-yu.github.io/assets/pdf/yis-cp23-preprint.pdf" target="_blank">PDF</a>]
				</span>  
                        </div> 
                    </li>        
		    	    
		    <li>                    
                        <div id="yisnms-aaai23">  
                            <span class="title">
                                Eliminating The Impossible, Whatever Remains Must Be True
                            </span>
                            <span class="author">
                                <em>Jinqiang Yu,</em>
                                <a href="https://alexeyignatiev.github.io/" target="_blank">Alexey Ignatiev</a>,  
                                <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>,
                                <a href="https://research.vmware.com/researchers/nina-narodytska/" target="_blank">Nina Narodytska,</a>,
                                and <a href="https://jpmarquessilva.github.io/" target="_blank">Joao Marques-Silva</a>
                            </span>
                            <span class="venue">
                                <i>
                                37th AAAI Conference on Artificial Intelligence (AAAI), pp. 4123–4131, 2023 
				</i>
                            </span>
			     <span class="abstract.hidden">
			    <p>The rise of AI methods to make predictions and decisions has led to a pressing need for more explainable artificial intelligence (XAI) methods. One common approach for XAI is to produce a post-hoc explanation, explaining why a black box ML model made a certain prediction. Formal approaches to post-hoc explanations provide succinct reasons for <em>why</em> a prediction was made, as well as <em>why not</em> another prediction was made. But these approaches assume that features are independent and uniformly distributed. While this means that “why” explanations are correct, they may be longer than required. It also means the “why not” explanations may be suspect as the counterexamples they rely on may not be meaningful. In this paper, we show how one can apply background knowledge to give more succinct “why” formal explanations, that are presumably easier to interpret by humans, and give more accurate “why not” explanations. In addition, we show how to use existing rule induction techniques to efficiently extract background information from a dataset.</p>
			    </span>
                            <span class="links">
                                [<a href="https://arxiv.org/abs/2206.09551" target="_blank">arXiv</a>] 
                                [<a href="https://jinqiang-yu.github.io/assets/pdf/yisnms-aaai23-preprint.pdf" target="_blank">PDF</a>]
                            </span>  
                        </div> 
                    </li>        

		    <li>                    
                        <div id="yisb-jair21">  
                            <span class="title">
                                Learning Optimal Decision Sets and Lists with SAT
                            </span>
                            <span class="author">
                                <em>Jinqiang Yu,</em>
                                <a href="https://alexeyignatiev.github.io/" target="_blank">Alexey Ignatiev</a>,  
                                <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>,
                                and <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>
                            </span>
                            <span class="venue">
                                <i>
				Journal of Artificial Intelligence Research, 72, 1251-1279, 2021
                                </i>
                            </span>
			    <span class="abstract.hidden">
			    <p>Decision sets and decision lists are two of the most easily explainable machine learning models. Given the renewed emphasis on explainable machine learning decisions, both of these machine learning models are becoming increasingly attractive, as they combine small size and clear explainability. In this paper, we define size as the total number of literals in the SAT encoding of these rule-based models as opposed to earlier work that concentrates on the number of rules. In this paper, we develop approaches to computing minimum-size “perfect” decision sets and decision lists, which are perfectly accurate on the training data, and minimal in size, making use of modern SAT solving technology. We also provide a new method for determining optimal sparse alternatives, which trade off size and accuracy. The experiments in this paper demonstrate that the optimal decision sets computed by the SAT-based approach are comparable with the best heuristic methods, but much more succinct, and thus, more explainable. We contrast the size and test accuracy of optimal decisions lists versus optimal decision sets, as well as other state-of-the-art methods for determining optimal decision lists. Finally, we examine the size of average explanations generated by decision sets and decision lists.</p>
		            </span>
                            <span class="links">
                                [<a href="https://www.jair.org/index.php/jair/article/view/12719" target="_blank">HTML</a>] 
                                [<a href="https://jinqiang-yu.github.io/assets/pdf/yisb-jair21.pdf" target="_blank">PDF</a>]
                            </span>  
                        </div> 
                    </li>        
                    
                    <li>                    
                        <div id="yibs-corr20">  
                            <span class="title">
                                Optimal Decision Lists Using SAT
                            </span>
                            <span class="author">
                                <em>Jinqiang Yu,</em>
                                <a href="https://alexeyignatiev.github.io/" target="_blank">Alexey Ignatiev</a>,  
                                <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>,                        
                                and <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>
                            </span>
                            <span class="venue">
                                <i>
                                CoRR abs/2010.09919,
                                2020
                                </i>
                            </span>
			    <span class="abstract.hidden">
			    <p>Decision lists are one of the most easily explainable machine learning models. Given the renewed emphasis on explainable machine learning decisions, this machine learning model is increasingly attractive, combining small size and clear explainability. In this paper, we show for the first time how to construct optimal “perfect” decision lists which are perfectly accurate on the training data, and minimal in size, making use of modern SAT solving technology. We also give a new method for determining optimal sparse decision lists, which trade off size and accuracy. We contrast the size and test accuracy of optimal decisions lists versus optimal decision sets, as well as other state-of-the-art methods for determining optimal decision lists. We also examine the size of average explanations generated by decision sets and decision lists.</p>
			    </span>
                            <span class="links">
                                [<a href="https://arxiv.org/abs/2010.09919" target="_blank">HTML</a>] 
                                [<a href="https://jinqiang-yu.github.io/assets/pdf/yibs-corr20.pdf" target="_blank">PDF</a>]
                            </span>  
                        </div> 
                    </li>                    
                    
                    <li>
                        <div id="yisb-cp20">  
                            <span class="title">
                                Computing Optimal Decision Sets with SAT
                            </span>
                            <span class="author">
                                <em>Jinqiang Yu,</em>
                                <a href="https://alexeyignatiev.github.io/" target="_blank">Alexey Ignatiev</a>,  
                                <a href="https://people.eng.unimelb.edu.au/pstuckey/" target="_blank">Peter J. Stuckey</a>,
                                and <a href="https://research.monash.edu/en/persons/pierre-le-bodic" target="_blank">Pierre Le Bodic</a>
                            </span>
                            <span class="venue">
                                <i>26th International Conference on Principles and Practice of Constraint Programming (CP 2020)</i>
                            </span>
			    <span class="abstract.hidden">
				<p>As machine learning is increasingly used to help make decisions, there is a demand for these decisions to be explainable. Arguably, the most explainable machine learning models use decision rules. This paper focuses on decision sets, a type of model with unordered rules, which explains each prediction with a single rule. In order to be easy for humans to understand, these rules must be concise. Earlier work on generating optimal decision sets first minimizes the number of rules, and then minimizes the number of literals, but the resulting rules can often be very large. Here we consider a better measure, namely the total size of the decision set in terms of literals. So we are not driven to a small set of rules which require a large number of literals. We provide the first approach to determine minimum-size decision sets that achieve minimum empirical risk and then investigate sparse alternatives where we trade accuracy for size. By finding optimal solutions we show we can build decision set classifiers that are almost as accurate as the best heuristic methods, but far more concise, and hence more explainable.</p>
			    </span>
                            <span class="conference">
                                <i>
                                Lecture Notes in Computer Science,
                                vol.&thinsp;12333,
                                pp.&thinsp;952–970,
                                2020
                                </i>
                            </span>
                            <span class="links">
                                [<a href="http://arxiv.org/abs/2007.15140" target="_blank">arXiv</a>]
                                [<a href="https://doi.org/10.1007/978-3-030-58475-7_55" target="_blank">HTML</a>] 
                                [<a href="https://jinqiang-yu.github.io/assets/pdf/yisb-cp20-preprint.pdf" target="_blank">PDF</a>]
                            </span>
                        </div>
                    </li>
                                                
                </ol>
                
                <p class='subtitle'>
                    Education
                </p>
                <p class="info"> 
                    <ul>
                        <li style="font-size:18px"><b>Feb 2021 - Present:</b>  PhD, Optimisation Group, Department of Data Science & AI, Faculty of IT, Monash University</li>
                        <li style="font-size:18px"><b>Mar 2019 - Dec 2020:</b>  Master of Information Technology, Monash University</li>
                      
                    </ul>   
                </p>  
                
                <br>
                <br>
                <p class='subtitle'>
                    Awards
                </p>
                <p class="info"> 
                    <ul>
                        <li style="font-size:18px">Our paper “Computing Optimal Decision Sets with SAT” is selected for the <b>Best Paper Award</b> for the CP/ML Track CP 2020!</li>
                        <li style="font-size:18px">Monash Faculty of Information Technology International Postgraduate Research Scholarship</li>
                        <li style="font-size:18px">Monash Faculty of Information Technology Research Scholarship</li>
                    </ul>   
                </p>  
                
                <br>
                <br>
                <p class='subtitle'>
                    Skills
                </p>
                <p class="info"> 
                    <ul>
			<li style="font-size:18px">Proficient in Python, Java, R, SQL</li>
			<li style="font-size:18px">Familiar with C/C++, Spark, MongoDB, MATLAB, MiniZinc, and machine/deep learning models e.g. neural network, transformer, LLM, gradient boosted tree.</li>
			<li style="font-size:18px">Experience with data analysis, NLP, CV, and diverse libraries such as pandas, numpy, scikit‑learn, TensorFlow, PyTorch, and PySAT.</li>
			<!--<li style="font-size:18px"><b>Languages: </b>English, Cantonese, Mandarin </li>--!>
                    </ul>   
                </p>                  
            </div>
        </div>                                                      <!-- index ends here -->

                                                                    <!-- about strats here  -->
        <div id="about_scroll" class="pages "> 
            <div class="container main">
                <div class="row">
                    <div class="col-md-4 left" id="about_left">
                        <br>
                        <br>
                        <br>
                        <br>
                        <img class="img-responsive img-rabbit" src="assets/images/home.jpg">
                    </div>

                    <div class="col-md-6 right" id="about_right">
                        <a href="#index" class="btn btn-rabbit back"> <i class="fa fa-angle-left" aria-hidden="true"></i> Back to home </a>
                        <div id="watermark">
                            <h2 class="page-title" text-center>About</h2>
                            <div class="marker">a</div>
                        </div>
                        
                    </div>
                    
                </div>
            </div>            
        </div>                                                                
                                                                    <!-- About ends here -->
        
        
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
        <script src="assets/js/bootstrap.min.js"></script>
        <script src="assets/js/script.js"></script>
    
    </body>
</html>
